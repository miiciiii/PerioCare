{% extends 'base/index.html' %}

{% block content %}

<div class="container py-5 text-center text-dark">
  <!-- Call Header -->
  <h4 class="mb-2">On Call with <span class="text-info">AI Assistant</span></h4>
  <small id="call-timer" class="mb-4 d-block text-muted">Call Duration: 00:00</small>

  <!-- Soundwave Animation -->
  <div class="soundwave" id="soundwave">
    <!-- Pulsing Rings -->
    <span class="ring"></span>
    <span class="ring"></span>
    <span class="ring"></span>

    <!-- Central Spikes -->
    <div class="spike-container">
      <div class="spike"></div>
      <div class="spike"></div>
      <div class="spike"></div>
      <div class="spike"></div>
      <div class="spike"></div>
    </div>
  </div>

  <div id="ai-status" class="text-info mb-4">Listening...</div>

    <!-- Chat Display -->
    <div id="chat-container" class="bg-white text-dark rounded shadow-sm p-3 mx-auto mb-4"
        style="max-width: 600px; height: 250px; overflow-y: auto;">
    <div id="chat-body" class="d-flex flex-column gap-2"></div>
    </div>


  <!-- Chat Mode Button -->
  <a href="{% url 'chat' %}" class="btn btn-outline-dark">Switch to Chat Mode</a>
  
    <!-- Finish Button -->
  <div class="text-center mt-4">
    <a href="{% url 'response' %}" class="btn btn-outline-dark">Finish Call</a>
  </div>
</div>

<script>
const chatBox = document.getElementById('chat-body');
const soundwave = document.getElementById('soundwave');
const aiStatus = document.getElementById('ai-status');

let recognition;
let isSpeaking = false;
let shouldListen = true;

function setupRecognition() {
    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'en-US';
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onstart = () => {
        aiStatus.textContent = "Listening...";
    };

    recognition.onresult = (event) => {
    const transcript = event.results[0][0].transcript.trim();
    appendMessage(transcript, 'user');

    fetch("{% url 'openai_api' %}", {
        method: "POST",
        headers: {
        "X-CSRFToken": "{{ csrf_token }}",
        "Content-Type": "application/json"
        },
        body: JSON.stringify({
        messages: [
            { role: "user", content: transcript }
        ]
        })
    })
    .then(response => response.json())
    .then(data => {
        const aiReply = data.response || "AI did not respond.";
        appendMessage(aiReply, 'ai');
        speak(aiReply);
    })
    .catch(error => {
        console.error("Voice fetch error:", error);
    });
    };

    recognition.onerror = (event) => {
        console.warn("Speech recognition error:", event.error);
        if (shouldListen && !isSpeaking) restartRecognition();
    };

    recognition.onend = () => {
        if (shouldListen && !isSpeaking) restartRecognition();
    };
}

function startRecognition() {
    if (!recognition) setupRecognition();
    try {
        recognition.start();
    } catch (e) {
        console.warn("Recognition start error:", e.message);
    }
}

function stopRecognition() {
    if (recognition) {
        try {
            recognition.stop();
        } catch (e) {
            console.warn("Recognition stop error:", e.message);
        }
    }
}

function restartRecognition(delay = 500) {
    setTimeout(() => {
        if (!isSpeaking && shouldListen) {
            startRecognition();
        }
    }, delay);
}

function speak(text) {
    stopRecognition();
    isSpeaking = true;
    const synth = window.speechSynthesis;
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'en-US';

    aiStatus.textContent = "AI is speaking...";
    soundwave.style.animationPlayState = 'running';

    synth.cancel(); // in case previous speech is still running
    synth.speak(utterance);

    utterance.onend = () => {
        isSpeaking = false;
        soundwave.style.animationPlayState = 'paused';
        aiStatus.textContent = "Listening...";
        restartRecognition(800);
    };
}

function appendMessage(text, sender) {
    const msg = document.createElement('div');
    msg.className = `d-flex ${sender === 'user' ? 'justify-content-end' : 'justify-content-start'}`;
    msg.innerHTML = `
        <span class="badge ${sender === 'user' ? 'bg-primary' : 'bg-success'} text-wrap text-start"
              style="max-width: 80%; white-space: normal;">
            ${sender === 'user' ? 'You' : 'AI'}: ${text}
        </span>`;
    chatBox.appendChild(msg);
    chatBox.scrollTop = chatBox.scrollHeight;
}

function startCallTimer() {
    const timerElement = document.getElementById("call-timer");
    let seconds = 0;
    setInterval(() => {
        seconds++;
        const mins = String(Math.floor(seconds / 60)).padStart(2, '0');
        const secs = String(seconds % 60).padStart(2, '0');
        timerElement.textContent = `Call Duration: ${mins}:${secs}`;
    }, 1000);
}

window.onload = () => {
    soundwave.style.animationPlayState = 'paused';
    shouldListen = true;
    setTimeout(() => {
        startRecognition();
    }, 1000);
    startCallTimer();
};
</script>


{% endblock %}
