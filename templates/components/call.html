{% extends 'base/index.html' %}

{% block content %}

<div class="container py-5 text-center text-dark">
  <h4 class="mb-2">On Call with <span class="text-info">AI Assistant</span></h4>
  <small id="call-timer" class="mb-4 d-block text-muted">Call Duration: 00:00</small>

  <div class="soundwave" id="soundwave">
    <span class="ring"></span>
    <span class="ring"></span>
    <span class="ring"></span>

    <div class="spike-container">
      <div class="spike"></div>
      <div class="spike"></div>
      <div class="spike"></div>
      <div class="spike"></div>
      <div class="spike"></div>
    </div>
  </div>

  <div id="ai-status" class="text-info mb-4">Listening...</div>

  <div id="chat-container" class="bg-white text-dark rounded shadow-sm p-3 mx-auto mb-4"
       style="max-width: 600px; height: 250px; overflow-y: auto;">
    <div id="chat-body" class="d-flex flex-column gap-2"></div>
  </div>

  <a href="{% url 'chat' %}" class="btn btn-outline-dark">Switch to Chat Mode</a>

  <div class="text-center mt-4">
    <button id="endCallButton" class="btn btn-outline-dark">Finish Call</button>
  </div>
</div>

<script>
const chatBox = document.getElementById('chat-body');
const soundwave = document.getElementById('soundwave');
const aiStatus = document.getElementById('ai-status');

let recognition;
let isSpeaking = false;
let shouldListen = true;
let fullTranscript = "";

let messages = [];

// Store call_id if not set
if (!localStorage.getItem("call_id")) {
    localStorage.setItem("call_id", "{{ call_id|default:'0' }}");
}

function setupRecognition() {
    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'en-US';
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onstart = () => {
        aiStatus.textContent = "Listening...";
    };

    recognition.onresult = event => {
        const transcript = event.results[0][0].transcript.trim();

        const lastAIMessage = messages.slice().reverse().find(m => m.role === "assistant");
        const lastAIText = lastAIMessage ? lastAIMessage.content : "";

        appendMessage(transcript, 'user');
        messages.push({ role: "user", content: transcript });

        fetch("{% url 'openai_api' %}", {
            method: "POST",
            headers: {
                "X-CSRFToken": "{{ csrf_token }}",
                "Content-Type": "application/json"
            },
            body: JSON.stringify({ messages: messages })
        })
        .then(response => response.json())
        .then(data => {
            const aiReply = data.response || "AI did not respond.";
            const isFallback = data.is_fallback || false;

            appendMessage(aiReply, 'ai');
            messages.push({ role: "assistant", content: aiReply });

            speak(aiReply, isFallback);
        })
        .catch(error => {
            console.error("Voice fetch error:", error);
        });
    };

    recognition.onerror = event => {
        console.warn("Speech recognition error:", event.error);
        if (shouldListen && !isSpeaking) restartRecognition();
    };

    recognition.onend = () => {
        if (shouldListen && !isSpeaking) restartRecognition();
    };
}


function startRecognition() {
    if (!recognition) setupRecognition();
    try { recognition.start(); }
    catch (e) { console.warn("Recognition start error:", e.message); }
}

function stopRecognition() {
    if (recognition) {
        try { recognition.stop(); }
        catch (e) { console.warn("Recognition stop error:", e.message); }
    }
}

function restartRecognition(delay = 2000) {
    setTimeout(() => {
        if (!isSpeaking && shouldListen) startRecognition();
    }, delay);
}

function speak(text, isFallback = false) {
    stopRecognition();
    isSpeaking = true;
    aiStatus.textContent = "AI is speaking...";
    soundwave.style.animationPlayState = 'running';

    const synth = window.speechSynthesis;
    synth.cancel();

    const speakText = (message) => {
        return new Promise(resolve => {
            const utterance = new SpeechSynthesisUtterance(message);
            utterance.lang = 'en-US';
            utterance.onend = resolve;
            synth.speak(utterance);
        });
    };

    // Speak AI reply
    speakText(text)
    .then(() => {
        if (isFallback) {
            const prompt = "For better assistance, we recommend switching to Chat Mode. Do you want to switch now?";
            return speakText(prompt).then(() => {
                const confirmed = confirm(prompt);
                if (confirmed) {
                    window.location.href = "{% url 'chat' %}";
                }
            });
        }
    })
    .finally(() => {
        isSpeaking = false;
        soundwave.style.animationPlayState = 'paused';
        aiStatus.textContent = "Listening...";
        restartRecognition(1000); // ‚Üê safe delay to ensure echo clears
    });
}


function appendMessage(text, sender) {
    const msg = document.createElement('div');
    msg.className = `d-flex ${sender === 'user' ? 'justify-content-end' : 'justify-content-start'}`;
    msg.innerHTML = `
        <span class="badge ${sender === 'user' ? 'bg-primary' : 'bg-success'} text-wrap text-start"
              style="max-width: 80%; white-space: normal;">
            ${sender === 'user' ? 'You' : 'AI'}: ${text}
        </span>`;
    chatBox.appendChild(msg);
    chatBox.scrollTop = chatBox.scrollHeight;
    fullTranscript += `${sender === 'user' ? 'You' : 'AI'}: ${text}\n`;
}

function startCallTimer() {
    const timerElement = document.getElementById("call-timer");
    let seconds = 0;
    setInterval(() => {
        seconds++;
        const mins = String(Math.floor(seconds / 60)).padStart(2, '0');
        const secs = String(seconds % 60).padStart(2, '0');
        timerElement.textContent = `Call Duration: ${mins}:${secs}`;
    }, 1000);
}

document.getElementById("endCallButton").addEventListener("click", function () {
    const callId = localStorage.getItem("call_id");

    const redirectToResponse = () => {
        if (callId && !isNaN(Number(callId))) {
            window.location.href = `/backend/response/${callId}/`;
        } else {
            window.location.href = "/backend/call/";
        }
    };

    if (!callId || !fullTranscript.trim()) {
        localStorage.removeItem("call_id");
        redirectToResponse();
        return;
    }

    fetch("{% url 'save_conversation' %}", {
        method: "POST",
        headers: {
            "X-CSRFToken": "{{ csrf_token }}",
            "Content-Type": "application/json"
        },
        body: JSON.stringify({
            call_id: callId,
            full_transcript: fullTranscript
        })
    })
    .then(() => {
        localStorage.removeItem("call_id");
        redirectToResponse();
    })
    .catch(err => {
        console.error("Failed to save conversation:", err);
        redirectToResponse();
    });
});

window.onload = () => {
    soundwave.style.animationPlayState = 'paused';
    shouldListen = true;

    const initialMessage = "{{ initial_message|escapejs }}";
    if (initialMessage) {
        appendMessage(initialMessage, 'ai');
        speak(initialMessage);
    } else {
        startRecognition();
    }

    startCallTimer();
};


</script>


{% endblock %}
